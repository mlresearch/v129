---
title: Boosting-Based Reliable Model Reuse
crossref: acml20
abstract: 'We study the following model reuse problem: a learner needs to select a
  subset of models from a model pool to classify an unlabeled dataset without accessing
  the raw training data of the models. Under this situation, it is challenging to
  properly estimate the reusability of the models in the pool. In this work, we consider
  the model reuse protocol under which the learner receives specifications of the
  models, including reusability indicators to verify the modelsâ€™ prediction accuracy
  on any unlabeled instances. We propose MoreBoost, a simple yet powerful boosting
  algorithm to achieve effective model reuse under the idealized assumption that the
  reusability indicators are noise-free. When the reusability indicators are noisy,
  we strengthen MoreBoost with an active rectification mechanism, allowing the learner
  to query ground-truth indicator values from the model providers actively. The resulted
  MoreBoost.AR algorithm is guaranteed to significantly reduce the prediction error
  caused by the indicator noise. We also conduct experiments on both synthetic and
  benchmark datasets to verify the performance of the proposed approaches.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ding20a
month: 0
tex_title: Boosting-Based Reliable Model Reuse
firstpage: 145
lastpage: 160
page: 145-160
order: 145
cycles: false
bibtex_author: Ding, Yao-Xiang and Zhou, Zhi-Hua
author:
- given: Yao-Xiang
  family: Ding
- given: Zhi-Hua
  family: Zhou
date: 2020-09-25
address: 
container-title: Proceedings of The 12th Asian Conference on Machine Learning
volume: '129'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 9
  - 25
pdf: http://proceedings.mlr.press/v129/ding20a/ding20a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
