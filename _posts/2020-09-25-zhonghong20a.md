---
title: 'AARM: Action Attention Recalibration Module for Action Recognition'
crossref: acml20
abstract: 'Most of Action recognition methods deploy networks pretrained on image
  datasets, and a common limitation is that these networks hardly capture salient
  features of the video clip due to their training strategies. To address this issue,
  we propose Action Attention Recalibration Module (AARM), a lightweight but effective
  module which introduces the attention mechanism to process feature maps of the network.
  The proposed module is composed of two novel components: 1) convolutional attention
  submodule that obtains inter-channel attention maps and spatial-temporal attention
  maps during the convolutional stage, and 2) activation attention submodule that
  highlights the significant activations in the fully connected process. Based on
  ablation studies and extensive experiments, we demonstrate that AARM enables networks
  to be sensitive on informative parts and gain accuracy increasements, achieving
  the state-of-the-art performance on UCF101 and HMDB51.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhonghong20a
month: 0
tex_title: 'AARM: Action Attention Recalibration Module for Action Recognition'
firstpage: 97
lastpage: 112
page: 97-112
order: 97
cycles: false
bibtex_author: Zhonghong, Li and Yang, Yi and Ying, She and Jialun, Song and Yukun,
  Wu
author:
- given: Li
  family: Zhonghong
- given: Yi
  family: Yang
- given: She
  family: Ying
- given: Song
  family: Jialun
- given: Wu
  family: Yukun
date: 2020-09-25
address: 
container-title: Proceedings of The 12th Asian Conference on Machine Learning
volume: '129'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 9
  - 25
pdf: http://proceedings.mlr.press/v129/zhonghong20a/zhonghong20a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
